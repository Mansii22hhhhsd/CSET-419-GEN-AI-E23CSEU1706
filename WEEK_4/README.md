# CSET-419 â€“ Generative AI  
## Lab 4: Text Generation using RNN/LSTM and Transformer

### ðŸ“Œ Objective
To design and implement a simple text generation model that learns patterns from a given text corpus and generates meaningful text sequences.

---

## ðŸ§  Concepts Used
- Natural Language Processing (NLP)
- Tokenization (Word-level)
- Sequence Modeling
- RNN / LSTM Networks
- Transformer Architecture
- Text Generation

---

## ðŸ”¹ Component I: LSTM Based Text Generation

### Steps Performed:
1. Loaded and preprocessed text dataset  
2. Applied word-level tokenization  
3. Created input-output sequences  
4. Built an LSTM model using Keras  
5. Trained the model  
6. Generated new text using a seed sentence  

### Output:
The trained model successfully generated new text sequences based on learned patterns from the dataset.
